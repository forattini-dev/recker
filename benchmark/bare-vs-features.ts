/**
 * Bare Client vs Recker with Features Benchmark
 *
 * Shows the trade-offs:
 * - bare: fastest, but no features
 * - recker: slower per-request, but cache/dedup save network calls
 *
 * Key insight: Features pay for themselves when they reduce network calls
 */

import { run, bench, group } from 'mitata';
import { createServer } from 'node:http';
import { request as undiciRequest } from 'undici';
import { createBareClient } from '../src/bare.js';
import { createClient } from '../src/index.js';

const JSON_OUTPUT = process.env.BENCH_JSON === '1';

// Simulate realistic API response
const payload = {
  id: '123',
  name: 'Test User',
  email: 'test@example.com',
  profile: {
    bio: 'Lorem ipsum dolor sit amet',
    avatar: 'https://example.com/avatar.jpg',
    settings: { theme: 'dark', notifications: true }
  }
};

let requestCount = 0;

// Setup server that tracks request count
const server = createServer((req, res) => {
  requestCount++;

  // Simulate 20ms latency (realistic API)
  setTimeout(() => {
    res.writeHead(200, {
      'Content-Type': 'application/json',
      'Cache-Control': 'max-age=60'
    });
    res.end(JSON.stringify(payload));
  }, 20);
});

await new Promise<void>((resolve) => server.listen(0, resolve));
const port = (server.address() as any).port;
const url = `http://localhost:${port}`;

// Setup clients
const bareClient = createBareClient({ baseUrl: url });
const standardClient = createClient({ baseUrl: url });
const cachedClient = createClient({
  baseUrl: url,
  cache: {
    driver: 'memory',
    strategy: 'cache-first',
    ttl: 60_000
  }
});
const dedupClient = createClient({
  baseUrl: url,
  dedup: {}
});
const fullClient = createClient({
  baseUrl: url,
  cache: {
    driver: 'memory',
    strategy: 'cache-first',
    ttl: 60_000
  },
  dedup: {}
});

if (!JSON_OUTPUT) {
  console.log('â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—');
  console.log('â•‘        Bare Client vs Recker with Features (Cache/Dedup)          â•‘');
  console.log('â•‘                                                                   â•‘');
  console.log('â•‘  Server has 20ms simulated latency to show feature benefits       â•‘');
  console.log('â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n');
}

// â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
// Scenario 1: Single request (bare wins)
// â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

group('Single request (20ms latency)', () => {
  bench('bare client', async () => {
    const res = await bareClient.get('/single');
    await res.json();
  });

  bench('recker (standard)', async () => {
    await standardClient.get('/single').json();
  });

  bench('recker (with cache)', async () => {
    await cachedClient.get('/single-cached').json();
  });
});

// â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
// Scenario 2: Same endpoint hit 10 times (cache wins big!)
// â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

group('Same endpoint 10x (cache shines)', () => {
  bench('bare client (10 network calls)', async () => {
    for (let i = 0; i < 10; i++) {
      const res = await bareClient.get('/repeated');
      await res.json();
    }
  });

  bench('recker standard (10 network calls)', async () => {
    for (let i = 0; i < 10; i++) {
      await standardClient.get('/repeated').json();
    }
  });

  bench('recker cached (1 network + 9 cache hits)', async () => {
    // Use unique path per benchmark iteration to ensure fresh cache
    const path = `/cached-${Date.now()}-${Math.random()}`;
    for (let i = 0; i < 10; i++) {
      await cachedClient.get(path).json();
    }
  });
});

// â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
// Scenario 3: 10 parallel requests to same endpoint (dedup wins!)
// â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

group('10 parallel to same endpoint (dedup shines)', () => {
  bench('bare client (10 network calls)', async () => {
    await Promise.all(
      Array(10).fill(null).map(() => bareClient.get('/parallel').then(r => r.json()))
    );
  });

  bench('recker standard (10 network calls)', async () => {
    await Promise.all(
      Array(10).fill(null).map(() => standardClient.get('/parallel').json())
    );
  });

  bench('recker dedup (1 network call, 9 shared)', async () => {
    // Use unique path per benchmark iteration
    const path = `/dedup-${Date.now()}-${Math.random()}`;
    await Promise.all(
      Array(10).fill(null).map(() => dedupClient.get(path).json())
    );
  });

  bench('recker full (cache + dedup)', async () => {
    const path = `/full-${Date.now()}-${Math.random()}`;
    await Promise.all(
      Array(10).fill(null).map(() => fullClient.get(path).json())
    );
  });
});

// â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
// Scenario 4: Mixed workload (real-world simulation)
// â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

group('Real-world: 5 unique + 5 repeated endpoints', () => {
  bench('bare client (10 network calls)', async () => {
    // 5 unique endpoints
    for (let i = 0; i < 5; i++) {
      const res = await bareClient.get(`/unique-${i}`);
      await res.json();
    }
    // 5 repeated calls to same endpoint
    for (let i = 0; i < 5; i++) {
      const res = await bareClient.get('/common');
      await res.json();
    }
  });

  bench('recker cached (5 unique + 1 cached = 6 network calls)', async () => {
    const uniqueBase = `/rw-${Date.now()}`;
    // 5 unique endpoints
    for (let i = 0; i < 5; i++) {
      await cachedClient.get(`${uniqueBase}-${i}`).json();
    }
    // 5 repeated calls - first hits network, rest hit cache
    for (let i = 0; i < 5; i++) {
      await cachedClient.get(`${uniqueBase}-common`).json();
    }
  });
});

await run({
  avg: true,
  format: JSON_OUTPUT ? 'json' : undefined,
  colors: !JSON_OUTPUT,
  min_max: true,
  percentiles: true,
});

server.close();

if (!JSON_OUTPUT) {
  console.log('\nâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•');
  console.log('                        KEY INSIGHTS                                ');
  console.log('â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•');
  console.log('');
  console.log('â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”');
  console.log('â”‚  BARE CLIENT                                                    â”‚');
  console.log('â”‚  âœ“ Fastest per-request (~0% overhead vs undici)                 â”‚');
  console.log('â”‚  âœ— No cache - every request hits the network                    â”‚');
  console.log('â”‚  âœ— No dedup - parallel requests multiply network calls          â”‚');
  console.log('â”‚  âœ— No retry - failures are your problem                         â”‚');
  console.log('â”‚  âœ— No hooks/middleware - no request transformation              â”‚');
  console.log('â”‚  â†’ Best for: Simple scripts, one-off requests, max throughput   â”‚');
  console.log('â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜');
  console.log('');
  console.log('â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”');
  console.log('â”‚  RECKER WITH FEATURES                                           â”‚');
  console.log('â”‚  âœ— ~2x slower per-request overhead                              â”‚');
  console.log('â”‚  âœ“ Cache saves network calls on repeated requests               â”‚');
  console.log('â”‚  âœ“ Dedup collapses parallel requests to single network call     â”‚');
  console.log('â”‚  âœ“ Retry handles transient failures automatically               â”‚');
  console.log('â”‚  âœ“ Hooks enable auth, logging, transformation                   â”‚');
  console.log('â”‚  â†’ Best for: Production apps, APIs with repeated data           â”‚');
  console.log('â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜');
  console.log('');
  console.log('ðŸ’¡ Rule of thumb:');
  console.log('   - 1 request to 1 endpoint? â†’ Use bare client');
  console.log('   - Same data requested multiple times? â†’ Use cache');
  console.log('   - Parallel requests to same endpoint? â†’ Use dedup');
  console.log('   - Production API client? â†’ Use recker with features');
  console.log('');
}
